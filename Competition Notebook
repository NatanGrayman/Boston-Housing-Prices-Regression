{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5407,"databundleVersionId":868283,"sourceType":"competition"}],"dockerImageVersionId":30458,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"raw","source":"# **House Prices: Advanced Regression Techniques**\n\n**Authors:**\n\n* [Natan Grayman (2344104)](https://www.kaggle.com/natangrayman)\n* [Gilad Kangisser (2367017)](https://www.kaggle.com/giladkangisser)\n* [Daron Sender (2332451)](https://www.kaggle.com/daronsender)\n* [Ruth-Ann Wright (2351852)](https://www.kaggle.com/ruthannwright)\n\nChatGPT was used to generate some code and helped provide comments on other code\n\n# **Introduction**\nWelcome to this machine learning notebook on House Prices: Advanced Regression Techniques. This notebook is intended to be a practical project for an introductory machine learning course, to predict the sale prices of houses based on various features. The dataset used in this notebook is based on the Ames Housing dataset, which was compiled by Dean De Cock for use in data science education.\n\nIn this notebook, we will explore various machine learning algorithms to predict house prices. Specifically, we will be implementing and comparing the performance of linear regression, K-Nearest Neighbours (KNN), and Random Forest models. To evaluate the performance of each model, we will utilize the Root Mean Square Error (RMSE). The RMSE will allow us to compare the accuracy of each model and determine which model provides the best prediction of house prices.\n\nAdditionally, this project will involve the full machine learning pipeline, including data cleaning and pre-processing, feature selection, model selection and tuning, and evaluation. We will also be using various visualization techniques to explore and present our findings.\n\nOur goal is to find the most suitable regression model for predicting house prices and to identify the most relevant features contributing to the predictions. We will use various data processing and feature selection techniques to optimize the model's performance.\n\nLet's get started!\n\n**The following is a submission to the Kaggle House Prices competition. This notebook will explore the following:**\n\n1. [Exploratory Data Analysis (EDA)](#section-one)\n> * [Loading the Libraries and the Data](#section-one-a)\n> All the libraries are loaded at the start, to prevent them having to be loaded later on.\n> * [Exploring Dataset](#section-one-b):\n> This will handle exploring the attributes and data for the [training](#section-one-b-1) and [testing](#section-one-ab-2) datasets.\n> * [Handling Target Feature](#section-one-v):\n> The skewness and kurtosis of the target will be evaluated and processed.\n2. [Regression Models](#section-two)\n> * [Linear Regression](#section-two-a)\n> * [K-Nearest Neighbours (KNN)](#section-two-b)\n> * [Decision Trees](#section-two-c)\n> * [Ridge](#section-two-d)\n> * [Lasso](#section-two-e)\n3. [Data Processing](#section-three)\n> * [Organising Data](#section-three-a):\n> Data needs to be separated into subtypes. The rough [initial](#section-three-a-1) and the tuned [final](#section-three-a-2) separations are outlined.\n> * [Combining Train and Test datasets](#section-three-b):\n> In order to avoid duplicate code, all data processing was done a combined data set.\n> * [Finding Inter-Feature Dependencies](#section-three-c):\n> The dependencies of the features have implications when creating or deleting features because some features existence could be linked to another, even though the data in each feature is not necessarily correlated.\n> * [Null Data Handling](#section-three-d):\n> The value and accuracy of the models is highly dependant on the data used to train the models. Null data can either mean that the feature does not exist for the entry, or there is an error. The features with [null data was displayed](#section-three-d-1), missing data due to [errors in entries](#section-three-d-2) were evaluated & imputed, and ['NaN' was replaced](#section-three-d-3) with a more suitable value.\n> * [Running Models before Feature Selection](#section-three-e):\n> The compete dataset was used to train an initial model, before feature selection takes place.\n4. [Feature Selection](#section-four)\n> * [Fix the Skewness of the Data](#section-four-a):\n> Highly-skewed features manipulate the regression line. Scaling the data helps accurately model the fit.\n> * [Filtering High-NaN Features](#section-four-b):\n> Features that are significantly empty, likely do not contribute to the model and, therefore, increase the dimensionality and error in the model.\n> * [Filtering Dominant Categories](#section-four-c):\n> Nominal categories that are highly skewed towards a certain classification do not show the relationship between a category and the target. Therefore, these are not relevant to the regression models.\n> * [Feature Manipulation](#section-four-d):\n> Data in a set can intelligently be used in order to create more useful [novel features](#section-four-d-1). However, the combination of [legacy features](#section-four-d-2) used to create new features AND the new feature can shift the weighting of related features and increase dimensions, so these were removed.\n> * [Filtering Low-Relation Features](#section-four-e):\n> The predicted correlation of features to the target is important to train a model. [Categorical](#section-four-e-1) and [Numerical](#section-four-e-2) data used different means to evaluate the importance of a feature to the target, and was filtered.\n> * [Filtering Multicollinear Features](#section-four-f):\n> Intercorrelation between independent predictors can cause the regression line to shift. Removing multicollinear features ensures that independent features do not disproportionately impact the regression of models.\n5. [Results](#section-five)\n> * Results of the regression techniques are displayed and recorded.","metadata":{}},{"cell_type":"markdown","source":"<a id=\"section-one\"></a>\n# **1. Exploratory Data Analysis (EDA)**","metadata":{}},{"cell_type":"markdown","source":"<a id=\"section-one-a\"></a>\n## **Loadding the Librarires and Data**\n","metadata":{}},{"cell_type":"markdown","source":"Before we begin analyzing the data, we need to load the necessary Python libraries that we will be using in this notebook. The code snippet below shows how we can import and load the required libraries. This includes numpy and pandas for data processing and manipulation, matplotlib and seaborn for visualization, scipy for statistical analysis, os for system features, and sklearn for machine learning modeling. We also suppress various types of warnings that may arise during the analysis using the warnings module.","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # plotting\nimport seaborn as sns # statistical visualisations\nfrom scipy import stats\nimport os # system features\nimport warnings # suppress warnings\n%matplotlib inline   \nsns.set()   #Default settings \n\n#init\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\nwarnings.filterwarnings(\"ignore\", category=RuntimeWarning)\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\nfrom pandas.core.common import SettingWithCopyWarning\nwarnings.filterwarnings(\"ignore\", category=SettingWithCopyWarning)\nwarnings.filterwarnings(\"ignore\", category=SettingWithCopyWarning)\nfrom sklearn.exceptions import ConvergenceWarning\nwarnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n\n#for Linear Regression model\nfrom sklearn.linear_model import LinearRegression\nimport sklearn\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.linear_model import ElasticNetCV, LassoCV, RidgeCV, Ridge, Lasso, ElasticNet\nfrom sklearn.svm import SVR\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import GradientBoostingRegressor, BaggingRegressor","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-08T01:58:38.875998Z","iopub.execute_input":"2023-05-08T01:58:38.877159Z","iopub.status.idle":"2023-05-08T01:58:38.894675Z","shell.execute_reply.started":"2023-05-08T01:58:38.877097Z","shell.execute_reply":"2023-05-08T01:58:38.893596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The data is provided to us in CSV (Comma Separated Values) format. We will use the pandas library to read in the data as DataFrame objects. The code snippet below shows how we can read in the training and testing data and assign them to train_df and test_df variables, respectively. We also give these DataFrame objects names of \"Training Set\" and \"Testing Set\" for identification purposes:","metadata":{}},{"cell_type":"code","source":"# reading train data\ntrain_df = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/train.csv')\ntrain_df.name = \"Training Set\"\n\n# reading test data\ntest_df = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/test.csv')\ntest_df.name = \"Testing Set\"","metadata":{"execution":{"iopub.status.busy":"2023-05-08T01:06:12.298168Z","iopub.execute_input":"2023-05-08T01:06:12.298958Z","iopub.status.idle":"2023-05-08T01:06:12.390247Z","shell.execute_reply.started":"2023-05-08T01:06:12.298910Z","shell.execute_reply":"2023-05-08T01:06:12.388871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"section-one-b\"></a>\n## **Exploring Dataset**","metadata":{}},{"cell_type":"markdown","source":"The ID column is dropped as it does not add any value to the learning models. The ID column for the test data is stored in a variable id_num, which is required for the final submission .csv.  ","metadata":{}},{"cell_type":"code","source":"# dropping ID column\ntrain_df.drop(['Id'], axis=1, inplace = True)\nid_num = test_df['Id']\ntest_df.drop(['Id'], axis=1, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2023-05-08T01:06:12.393542Z","iopub.execute_input":"2023-05-08T01:06:12.394581Z","iopub.status.idle":"2023-05-08T01:06:12.410274Z","shell.execute_reply.started":"2023-05-08T01:06:12.394520Z","shell.execute_reply":"2023-05-08T01:06:12.408879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"section-one-b-1\"></a>\n### **Training Set**\nFirstly we examine the training set by printing out its head, examining the different data types and then using the panda's describe function. ","metadata":{}},{"cell_type":"code","source":"# previewing the data\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-08T01:06:12.414233Z","iopub.execute_input":"2023-05-08T01:06:12.414748Z","iopub.status.idle":"2023-05-08T01:06:12.456414Z","shell.execute_reply.started":"2023-05-08T01:06:12.414690Z","shell.execute_reply":"2023-05-08T01:06:12.455153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checking data types\ntrain_df.info()","metadata":{"execution":{"iopub.status.busy":"2023-05-08T01:06:12.458257Z","iopub.execute_input":"2023-05-08T01:06:12.459041Z","iopub.status.idle":"2023-05-08T01:06:12.486629Z","shell.execute_reply.started":"2023-05-08T01:06:12.458992Z","shell.execute_reply":"2023-05-08T01:06:12.485291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# description of numerical train_data\ntrain_df.describe()","metadata":{"execution":{"iopub.status.busy":"2023-05-08T01:06:12.488304Z","iopub.execute_input":"2023-05-08T01:06:12.489031Z","iopub.status.idle":"2023-05-08T01:06:12.597363Z","shell.execute_reply.started":"2023-05-08T01:06:12.488984Z","shell.execute_reply":"2023-05-08T01:06:12.596436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"section-one-a-2\"></a>\n### **Testing Set**\nSimilarly, we also look at the testing set. ","metadata":{}},{"cell_type":"code","source":"# previewing the data\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-08T01:06:12.598849Z","iopub.execute_input":"2023-05-08T01:06:12.599521Z","iopub.status.idle":"2023-05-08T01:06:12.624822Z","shell.execute_reply.started":"2023-05-08T01:06:12.599483Z","shell.execute_reply":"2023-05-08T01:06:12.623335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checking data types\ntest_df.info()","metadata":{"execution":{"iopub.status.busy":"2023-05-08T01:06:12.626523Z","iopub.execute_input":"2023-05-08T01:06:12.626906Z","iopub.status.idle":"2023-05-08T01:06:12.649553Z","shell.execute_reply.started":"2023-05-08T01:06:12.626869Z","shell.execute_reply":"2023-05-08T01:06:12.648624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# description of numerical test_df\ntest_df.describe()","metadata":{"execution":{"iopub.status.busy":"2023-05-08T01:06:12.651030Z","iopub.execute_input":"2023-05-08T01:06:12.651454Z","iopub.status.idle":"2023-05-08T01:06:12.768858Z","shell.execute_reply.started":"2023-05-08T01:06:12.651417Z","shell.execute_reply":"2023-05-08T01:06:12.767703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"section-one-b\"></a>\n## **Handling Target Feature**","metadata":{}},{"cell_type":"markdown","source":"Before building the model, it is important to consider the target variable - which is sale price. We firstly extract it from the test data frame and then plot it to show its distribution. ","metadata":{}},{"cell_type":"code","source":"target = train_df['SalePrice']\ntrain_df.drop(columns = ['SalePrice'], inplace = True)","metadata":{"execution":{"iopub.status.busy":"2023-05-08T01:06:12.772840Z","iopub.execute_input":"2023-05-08T01:06:12.773834Z","iopub.status.idle":"2023-05-08T01:06:12.781777Z","shell.execute_reply.started":"2023-05-08T01:06:12.773782Z","shell.execute_reply":"2023-05-08T01:06:12.780743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The following distribution plot shows that the data is positively skewed, having a long right tial. The skewness value is 1.882876 while the kurtosis value is 6.536282. The high kurtosis value indicates that it has a high concentration of data in its tails.  ","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots()\nsns.distplot(target, ax=ax)\nax.set_title(\"Distribution of SalePrice\")\n# skewness and kurtosis\nprint(\"Skewness: %f\" % target.skew())\nprint(\"Kurtosis: %f\" % target.kurt())","metadata":{"execution":{"iopub.status.busy":"2023-05-08T01:06:12.783151Z","iopub.execute_input":"2023-05-08T01:06:12.783539Z","iopub.status.idle":"2023-05-08T01:06:13.241173Z","shell.execute_reply.started":"2023-05-08T01:06:12.783506Z","shell.execute_reply":"2023-05-08T01:06:13.239918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To improve performace of the algorithims the data is logged. This reduces the skewness and kurtosis of the target variable. This is important as skewness and high outliers make it hard for the model to accurately predict the target as there are few training examples in those regions. To reduce the skewness of the data the natural log of it is taken. As the results display, this has greatly reduced the skewness of the target variable. ","metadata":{}},{"cell_type":"code","source":"target_log = np.log1p(target)\nfig, ax = plt.subplots()\nsns.distplot(target, ax=ax)\nax.set_title(\"Distribution of SalePrice after Log\")\n# skewness and kurtosis\nprint(\"Skewness: %f\" % target_log.skew())\nprint(\"Kurtosis: %f\" % target_log.kurt())","metadata":{"execution":{"iopub.status.busy":"2023-05-08T01:06:13.242573Z","iopub.execute_input":"2023-05-08T01:06:13.242955Z","iopub.status.idle":"2023-05-08T01:06:13.672305Z","shell.execute_reply.started":"2023-05-08T01:06:13.242914Z","shell.execute_reply":"2023-05-08T01:06:13.671207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"section-two\"></a>\n# **2. Regression Models**\nDefining them here allows for them to be called throughout the data processing stage, so that one can tell if it improves them or not. The three models chosen are Linear Regresssion, K-Nearest Neighbours and Decisions trees. For Decision Trees the Random Forest Alogorithim was used. For Linear Regression, hyperparameter tuning was done with Ridge, Lasso, Elastic Net. ","metadata":{}},{"cell_type":"markdown","source":"<a id=\"section-two-a\"></a>\n## **Linear Regression**\nLinear Regression is one of the simplest and most popular statistical techniques used in machine learning. It finds the relationship between a dependent variable (labelled the target variable) and the one or more independent variables (known as the predictor variable and labbeled as X_train in this notebook). Once the best-fitting linear equation that describes the relationship is found, it can be used to predict the target variable for unseen data. \n\nThe following function, 'linear_regression', is used to to indicate the perfomance of linear_regression during different stages of the data processing and feature selection. It uses the Normal Equation and not the Gradient Descent for learning the target values from the data features. \n\nThe metric used to determine how well the model is performing is the root mean squared error (RMSE). This was chosen over the R2 metric as it is what the competition score is bassed on. To calculate the RMSE error, square root of the MSE is determined. In order to do this, X_test and t_test are requried to be passed into this function as well. ","metadata":{}},{"cell_type":"code","source":"def linear_regression(X_train,X_test, t_train, t_test):\n    Linear_reg = LinearRegression()\n    Linear_reg.fit(X_train, t_train)\n    print('Coefficients Linear Regression: ', Linear_reg.intercept_)\n    print('Intercept Linear Regression: ', Linear_reg.intercept_)\n    t_pred = Linear_reg.predict(X_test)\n    rmse = np.sqrt(np.mean((t_pred - t_test)**2))\n    print(f\"RMSE Linear Regression: {rmse}\")\n    return rmse","metadata":{"execution":{"iopub.status.busy":"2023-05-08T01:06:13.673850Z","iopub.execute_input":"2023-05-08T01:06:13.674490Z","iopub.status.idle":"2023-05-08T01:06:13.681514Z","shell.execute_reply.started":"2023-05-08T01:06:13.674453Z","shell.execute_reply":"2023-05-08T01:06:13.680230Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"section-two-b\"></a>\n## **K-Nearest Neighbours (KNN)**","metadata":{}},{"cell_type":"markdown","source":"In this code block, a K-Nearest Neighbors (KNN) regression model is being trained and evaluated using the provided data. KNN is a non-parametric and instance-based learning algorithm that can be used for both regression and classification tasks.\n\n### Model Selection and Training\nThe function `knn` takes four parameters: the training and testing input features (`X_train`, `X_test`) and the training and testing target values (`t_train`, `t_test`). The scoring metric used for evaluation is the negative mean squared error (`neg_mean_squared_error`), which is a common metric for regression tasks.\n\nA 3-fold cross-validation (`nr_cv = 3`) is used to assess the model's performance on the training data. Grid search is applied to find the best combination of hyperparameters for the KNN model, using the `GridSearchCV` function from the `sklearn` library. The hyperparameters considered in the search are:\n\n- `'n_neighbors'`: The number of nearest neighbors to include in the majority of the voting process. It is set to [3, 4, 5, 6, 7, 10, 15].\n- `'weights'`: The weight function used in prediction. It can be either `'uniform'` (all points in each neighborhood are weighted equally) or `'distance'` (weights are assigned based on the inverse of the distance from the query point).\n- `'algorithm'`: The algorithm used to compute the nearest neighbors. Options include `'ball_tree'`, `'kd_tree'`, and `'brute'`. These algorithms have different time and space complexities, depending on the data's structure.\n\n### Model Evaluation\nOnce the best hyperparameters are found, the KNN model is retrained using them, and predictions are made for the test data (`X_test`). The root mean squared error (RMSE) is calculated by comparing the predicted values (`pred_knn`) with the actual target values (`t_test`). The RMSE is then printed and returned by the function. This error metric provides an idea of how well the KNN model performs on the test data. ","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import mean_squared_error\n\n\ndef knn(X_train, X_test, t_train, t_test):\n    score_calc = 'neg_mean_squared_error'\n    # setting the number of cross validations used in the Model part \n    nr_cv = 3\n    param_grid = {'n_neighbors' : [3,4,5,6,7,10,15] ,    \n              'weights' : ['uniform','distance'] ,\n              'algorithm' : ['ball_tree', 'kd_tree', 'brute']}\n    knn = GridSearchCV(KNeighborsRegressor(), param_grid, cv=nr_cv, refit=True, verbose=1, scoring = score_calc)\n    knn.fit(X_train, t_train)\n    print(knn.best_estimator_)\n    pred_knn = knn.predict(X_test)\n    rmse = np.sqrt(mean_squared_error(t_test,pred_knn))\n    print(\"RMSE K-Nearest Neighbours: \", rmse)\n    return rmse\n","metadata":{"execution":{"iopub.status.busy":"2023-05-08T01:06:13.683943Z","iopub.execute_input":"2023-05-08T01:06:13.684499Z","iopub.status.idle":"2023-05-08T01:06:13.694288Z","shell.execute_reply.started":"2023-05-08T01:06:13.684450Z","shell.execute_reply":"2023-05-08T01:06:13.693252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"section-two-c\"></a>\n## **Random Forest**","metadata":{}},{"cell_type":"markdown","source":"In this code block, we define a function `random_forest_regression` that trains a RandomForestRegressor model using grid search for hyperparameter optimization. The function takes the training and testing data as input and returns the root mean squared error (RMSE) of the predictions.\n\n1. We import the RandomForestRegressor class from the `sklearn.ensemble` module.\n\n2. Inside the function, we create a RandomForestRegressor instance with a fixed random state (42) to ensure reproducibility of the results.\n\n3. We define a parameter grid for the grid search. The grid includes a combination of hyperparameters to be tested during the search:\n    - `n_estimators`: [50, 100] (number of trees in the forest)\n    - `max_depth`: [None, 20] (maximum depth of each tree)\n    - `min_samples_split`: [2, 5] (minimum number of samples required to split an internal node)\n    - `max_features`: ['auto'] (number of features to consider when looking for the best split)\n\n   These hyperparameters were chosen because they are among the most influential in determining the performance of a random forest model.\n\n4. We create a GridSearchCV instance with the RandomForestRegressor, the parameter grid, 5-fold cross-validation, and scoring based on the negative mean squared error. We set `verbose=1` to display the progress of the search and `n_jobs=-1` to use all available CPU cores for parallel computation.\n\n5. We fit the grid search to the training data, which will find the best combination of hyperparameters based on cross-validation.\n\n6. We extract the best hyperparameters found by the grid search and create a new RandomForestRegressor with these parameters.\n\n7. We fit the best random forest model to the training data and calculate the coefficient of determination (R-squared) on the training data to evaluate the model's performance.\n\n8. We make predictions on the test data using the best random forest model and calculate the RMSE, which serves as a measure of the model's performance on unseen data.\n\n9. Finally, we return the RMSE value as the output of the function.\n","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n\ndef random_forest_regression(X_train, X_test, t_train, t_test):\n\n    rf = RandomForestRegressor(random_state=42)\n\n    param_grid = {\n        'n_estimators': [50, 100],\n        'max_depth': [None, 20],\n        'min_samples_split': [2, 5],\n        'max_features': ['auto']\n    }\n\n    grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', verbose=1, n_jobs=-1)\n\n    grid_search.fit(X_train, t_train)\n\n    best_params = grid_search.best_params_\n\n    best_rf = RandomForestRegressor(**best_params)\n    best_rf.fit(X_train, t_train)\n\n    r_sq = best_rf.score(X_train, t_train)\n    print(f\"coefficient of determination: {r_sq}\")\n\n    t_pred = best_rf.predict(X_test)\n\n    # Calculate the RMSE\n    RMSE = np.sqrt(np.mean((t_pred - t_test) ** 2))\n    print(f\"RMSE: {RMSE}\")\n    return RMSE\n   ","metadata":{"execution":{"iopub.status.busy":"2023-05-08T01:06:13.696174Z","iopub.execute_input":"2023-05-08T01:06:13.696678Z","iopub.status.idle":"2023-05-08T01:06:13.706866Z","shell.execute_reply.started":"2023-05-08T01:06:13.696630Z","shell.execute_reply":"2023-05-08T01:06:13.705684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"section-two-d\"></a>\n## **Ridge**\nOrdinary Linear Regression does not have any hyperparameters to tune. This is why different regularization models are applied to linear regression which improve performance and allow for a better fit. \n\nRidge Regression is also known as L2 regularization. It is used to prevent overfitting of the linear regression. The goal of ridge regression is to shrink coefficients of independent variables twowards zero. The key difference between Ridge Regression and Linear Regression is the addition of a peanlty term to the cost function. The penalty term is proportional to the square of the magnitude of the coefficients and is controlled by the regularization hyperparameter (called alpha in the following code). As the value of lamba increases the coefficients are penalized more heavily. This can lead to a simpler model but also result in potentially higher bias. \n\nThe advantage of Rdige Regression is that it can be applied to a very high-dimensional dataset. As the results from the notebook show, the best RMSE score for Ridge Regression is before the number of features are reduced. \n\nThe ridge_model function created takes in the traning and test data as well as an array of hyperparameters labelled alphas. These hyperparameters are deliberately chosen to cover a large range of values as they are used for both the ridge_model and lasso_model. The function not only records the best alpha to use, but also plots the train and validation error for different hyperparameter values. It does not use a grid search but rather manually itterates through the different alphas and then stores the resulting errors. The error metric used is still the RMSE and is calculated by using the mean_squared_error function and settting 'squared' to be false. ","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import  Ridge\ndef ridge_model(X_train, t_train, X_val, t_val, alphas):\n    train_error = []\n    val_error = []\n    for alpha in alphas:\n        ridge = Ridge(alpha=alpha)\n        ridge.fit(X_train, t_train)\n        t_train_pred = ridge.predict(X_train)\n        t_val_pred = ridge.predict(X_val)\n        train_rmse = mean_squared_error(t_train, t_train_pred, squared=False)\n        val_rmse = mean_squared_error(t_val, t_val_pred, squared=False)\n        train_error.append(train_rmse)\n        val_error.append(val_rmse)\n        \n    # Plotting RMSE for different alpha values\n    plt.plot(alphas, train_error, label='Training RMSE')\n    plt.plot(alphas, val_error, label='Validation RMSE')\n    plt.xlabel('Alpha')\n    plt.ylabel('RMSE')\n    plt.legend()\n    plt.title('RMSE vs HyperParameters for Ridge Regression')\n    plt.show()\n    \n    # Print best alpha and corresponding RMSE\n    best_alpha = alphas[val_error.index(min(val_error))]\n    print(\"Best alpha For Ridge:\", best_alpha)\n    print(\"Ridge best RMSE Testing Value:\", min(val_error))\n    return min(val_error)","metadata":{"execution":{"iopub.status.busy":"2023-05-08T01:06:13.709439Z","iopub.execute_input":"2023-05-08T01:06:13.709908Z","iopub.status.idle":"2023-05-08T01:06:13.722002Z","shell.execute_reply.started":"2023-05-08T01:06:13.709862Z","shell.execute_reply":"2023-05-08T01:06:13.720966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"section-two-e\"></a>\n## **Lasso**\nLasso regression is a type of linear regression that uses L1 regularization to shrink the coefficients of the regression model towards zero. This technique is used to prevent overfitting and to improve the interpretability of the model. The L1 penalty function used in Lasso regression adds the absolute values of the coefficients to the loss function being optimized, in contrast to the L2 penalty function used in Ridge regression which adds the squared values of the coefficients. As a result, Lasso regression is often used in situations where it is suspected that only a small number of features are relevant to the prediction task, as it tends to drive the coefficients of the irrelevant features to zero, as it the case in this situation. \n\nLike the Ridge Regression, the Lasso Model works best before feature selection, as Lasso performs feature selection already. \n\nThe lasso_model function created takes in the traning and test data as well as an array of hyperparameters labelled alphas. These hyperparameters are deliberately chosen to cover a large range of values as they are used for both the ridge_model and lasso_model. The function not only records the best alpha to use, but also plots the train and validation error for different hyperparameter values. It does not use a grid search but rather manually itterates through the different alphas and then stores the resulting errors. The error metric used is still the RMSE and is calculated by using the mean_squared_error function and settting 'squared' to be false.","metadata":{}},{"cell_type":"code","source":"def lasso_model(X_train, t_train, X_val, t_val, alphas):\n    train_error = []\n    val_error = []\n    for alpha in alphas:\n        lasso = Lasso(alpha=alpha)\n        lasso.fit(X_train, t_train)\n        t_train_pred = lasso.predict(X_train)\n        t_val_pred = lasso.predict(X_val)\n        train_rmse = mean_squared_error(t_train, t_train_pred, squared=False)\n        val_rmse = mean_squared_error(t_val, t_val_pred, squared=False)\n        train_error.append(train_rmse)\n        val_error.append(val_rmse)\n      \n    # Plotting RMSE for different alpha values\n    plt.plot(alphas, train_error, label='Training RMSE')\n    plt.plot(alphas, val_error, label='Validation RMSE')\n    plt.xlabel('Alpha')\n    plt.ylabel('RMSE')\n    plt.title('RMSE vs Alpha for Lasso Regression')\n    plt.legend()\n    plt.show()\n    \n    # Print best alpha and corresponding RMSE\n    best_alpha = alphas[val_error.index(min(val_error))]\n    print('Lasso')\n    print(\"Best alpha for Lasso:\", best_alpha)\n    print(\"Lasso Best RMSE Testing Value:\", min(val_error))\n    return min(val_error)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-08T01:06:13.723743Z","iopub.execute_input":"2023-05-08T01:06:13.724396Z","iopub.status.idle":"2023-05-08T01:06:13.733924Z","shell.execute_reply.started":"2023-05-08T01:06:13.724333Z","shell.execute_reply":"2023-05-08T01:06:13.732703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Further Linear Regression Tuning and Regularization\nThis is a complex set of functions, and requires a long run time and should only be called when the Ridge and Lasso models get the best RMSE score for the initial Ridge and Lasso models. ","metadata":{}},{"cell_type":"code","source":"#these functions are required to work out the rmse and the rmse for cross-validation with k-folds\ndef rmsle(t_test, t_pred):\n    return np.sqrt(np.mean((t_pred - t_test)**2))\n\ndef cv_rmse(model, X, t):\n    kfolds = KFold(n_splits=10, shuffle=True, random_state=42)\n    rmse = np.sqrt(-cross_val_score(model, X, t, scoring=\"neg_mean_squared_error\", cv=kfolds))\n    return (rmse)","metadata":{"execution":{"iopub.status.busy":"2023-05-08T01:06:13.735372Z","iopub.execute_input":"2023-05-08T01:06:13.736116Z","iopub.status.idle":"2023-05-08T01:06:13.746458Z","shell.execute_reply.started":"2023-05-08T01:06:13.736079Z","shell.execute_reply":"2023-05-08T01:06:13.745313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The following code defines a function Linear_Regularization which performs advanced tuning for Linear Regression. This regularization is more refined than what is done in the Ridge_model and Lasso_model.\n\nThe function takes in the dataset all_data. It performs one-hot encoding to transform categorical features in the dataset into binary feature, and then extracts the train and test data.\n\nThe train dataset is split into a further train and test sections using the 'train_test_split' function from the sklearn library with a test size of 20%.\n\nNext three types of linear regression models are defined using pipelines, Ridge, Lasso and ElasticNet (which is a combination of Ridge and Lasso). Each Pipepline also includes data normalization using RoboustScaler. RobustScaler was deemed to be more effective than StandardScaler by creating another pipeline for Lasso using StandardScaler. The StandardScaler performed less optimally that the model with RoboustSclaer.\n\nThe use of cross-validation using 'KFold' from scikitlearn enhances the model by allowing the model to be tested on multiple subsets of the data. It helps to prevent overfitting to a particular dataset. \n\nGrid Search is used to find the best hyperparameters for Ridge Regression, Lasso Regression, ElasticNet Regression, and Gradient Boosting Regression models. For each model, a list of hyperparameters is defined - based on the hyperparameter estimated in the other Lasso and Ridge Model functinos. Then, we use Grid Search to evaluate the performance of each combination of hyperparameters and select the best hyperparameters for the model.\n\nThe code then prints out the best hyperparameters and the corresponding best score for each model. This allows us to see which model and which set of hyperparameters performed the best. \n\n","metadata":{}},{"cell_type":"code","source":"def Linear_Regularization (all_data):\n\n    all_data = pd.get_dummies(all_data).reset_index(drop=True)\n    X_train = all_data[:train_df.shape[0]]\n    X_test = all_data[train_df.shape[0]:]\n    y = target\n    #split data into training and test sets\n    X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X_train, target, test_size=0.2, random_state=42)\n    X_train.shape, y_train.shape, X_test.shape, y_test.shape\n    \n    kfolds_cross_validation = KFold(n_splits=10, shuffle=True, random_state=42)\n    \n    alphas_ridge = [8.5, 8.6, 8.7, 8.8, 8.9, 9, 9.1, 9.2, 9.3, 9.4, 9.5]\n    alphas_lasso = [5e-05, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008]\n    alphas_elasticnet = [0.0001,0.001, 0.01, 0.05, 0.1, 0.5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20, 50, 100]\n\n    ### use grid search to help find best alpha for models\n    # setup models\n    hyperparametersRidge = {'alpha': alphas_ridge}\n    search = GridSearchCV(Ridge(), hyperparametersRidge, cv=kfolds_cross_validation, scoring='neg_root_mean_squared_error', n_jobs=-1)\n    search.fit(X_train, y_train)\n    ridge_best_alpha = search.best_params_\n    print('Ridge Best Alpha:', ridge_best_alpha)\n    print('Ridge Best Score:', search.best_score_)\n\n    ## LASSO\n    hyperparametersLasso = {'alpha': alphas_lasso}\n    search = GridSearchCV(Lasso(), hyperparametersLasso, cv=kfolds_cross_validation, scoring='neg_root_mean_squared_error', n_jobs=-1)\n    search.fit(X_train, y_train)\n    lasso_best_alpha = search.best_params_\n    print('Lasso Best Alpha:', lasso_best_alpha)\n    print('Lasso Best Score:', search.best_score_)\n\n    ## ElasticNet\n    hyperparametersElasticNet = {'alpha': alphas_elasticnet}\n    search = GridSearchCV(ElasticNet(), hyperparametersElasticNet, cv=kfolds_cross_validation, scoring='neg_root_mean_squared_error', n_jobs=-1)\n    search.fit(X_train, y_train)\n    elasticnet_best_alpha = search.best_params_\n    print('ElasticNet Best Alpha:', elasticnet_best_alpha)\n    print('ElasticNet Best Score:', search.best_score_)\n\n    ## GradientBoostingRegressor\n    hyperparametersGradientBoostingRegressor = {'n_estimators': [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]}\n    search = GridSearchCV(GradientBoostingRegressor(), hyperparametersGradientBoostingRegressor, cv=kfolds_cross_validation, scoring='neg_root_mean_squared_error', n_jobs=-1)\n    search.fit(X_train, y_train)\n    gradientboostingregressor_best_alpha = search.best_params_\n    print('GradientBoostingRegressor Best Alpha:', gradientboostingregressor_best_alpha)\n    print('GradientBoostingRegressor Best Score:', search.best_score_)\n    ","metadata":{"execution":{"iopub.status.busy":"2023-05-08T01:06:13.747977Z","iopub.execute_input":"2023-05-08T01:06:13.748385Z","iopub.status.idle":"2023-05-08T01:06:13.765216Z","shell.execute_reply.started":"2023-05-08T01:06:13.748324Z","shell.execute_reply":"2023-05-08T01:06:13.763599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Linear_Regularization_With_RobustScaler is almost identical to Linear_Regularization function, except that it includes scaling the data with RobustScaler. This was chosen over using StandardScaler as it performed better","metadata":{}},{"cell_type":"code","source":"def Linear_Regularization_With_RobustScaler (all_data):\n\n    all_data = pd.get_dummies(all_data).reset_index(drop=True)\n    ## Add robust Scaler\n    scaler = RobustScaler()\n    all_data = scaler.fit_transform(all_data)\n    all_data = pd.DataFrame(all_data)\n    X_train = all_data[:train_df.shape[0]]\n    X_test = all_data[train_df.shape[0]:]\n    y = target\n    #split data into training and test sets\n    X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X_train, target, test_size=0.2, random_state=42)\n    X_train.shape, y_train.shape, X_test.shape, y_test.shape\n    \n    kfolds_cross_validation = KFold(n_splits=10, shuffle=True, random_state=42)\n    \n    alphas_ridge = [8.5, 8.6, 8.7, 8.8, 8.9, 9, 9.1, 9.2, 9.3, 9.4, 9.5]\n    alphas_lasso = [5e-05, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008]\n    alphas_elasticnet = [0.0001,0.001, 0.01, 0.05, 0.1, 0.5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20, 50, 100]\n\n    ### use grid search to help find best alpha for models\n    # setup models\n    hyperparametersRidge = {'alpha': alphas_ridge}\n    search = GridSearchCV(Ridge(), hyperparametersRidge, cv=kfolds_cross_validation, scoring='neg_root_mean_squared_error', n_jobs=-1)\n    search.fit(X_train, y_train)\n    ridge_best_alpha = search.best_params_\n    print('Ridge Best Alpha:', ridge_best_alpha)\n    print('Ridge Best Score:', search.best_score_)\n\n    ## LASSO\n    hyperparametersLasso = {'alpha': alphas_lasso}\n    search = GridSearchCV(Lasso(), hyperparametersLasso, cv=kfolds_cross_validation, scoring='neg_root_mean_squared_error', n_jobs=-1)\n    search.fit(X_train, y_train)\n    lasso_best_alpha = search.best_params_\n    print('Lasso Best Alpha:', lasso_best_alpha)\n    print('Lasso Best Score:', search.best_score_)\n\n    ## ElasticNet\n    hyperparametersElasticNet = {'alpha': alphas_elasticnet}\n    search = GridSearchCV(ElasticNet(), hyperparametersElasticNet, cv=kfolds_cross_validation, scoring='neg_root_mean_squared_error', n_jobs=-1)\n    search.fit(X_train, y_train)\n    elasticnet_best_alpha = search.best_params_\n    print('ElasticNet Best Alpha:', elasticnet_best_alpha)\n    print('ElasticNet Best Score:', search.best_score_)","metadata":{"execution":{"iopub.status.busy":"2023-05-08T01:06:13.767144Z","iopub.execute_input":"2023-05-08T01:06:13.767643Z","iopub.status.idle":"2023-05-08T01:06:13.784514Z","shell.execute_reply.started":"2023-05-08T01:06:13.767593Z","shell.execute_reply":"2023-05-08T01:06:13.783230Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Linear_Regularization_Solution that takes in all_data, RidgeAlpha, LassoAlpha, and ElasticNetAlpha as input arguments. As creates a .csv file as a solution\nIt preprocesses the all_data by converting categorical variables into numerical variables using one-hot encoding and scaling the data using RobustScaler, as from the previous functions Scaling the data improved the results.\n\nThe models are then fitted on the training data (X_train and y). Next, a blending function is defined that combines the predictions from the three models with different weights. The weights used in the blending function are 0.1 for ElasticNet, 0.2 for Lasso, and 0.7 for Ridge regression models. The weights are chosen based on how the models were deemed to have performed. Ideally a grid-search would have been used for this but there was insufficient time. Ridge is weighted heavier as no-warning was given about the model not converging. \n\nThe blend_models_predict function is then used to predict the target variable (SalePrice) on the training set (X_train) and calculate the root mean squared logarithmic error (RMSLE) score. Finally, the blended_score is printed to the console.","metadata":{}},{"cell_type":"code","source":"def Linear_Regularization_Solution(all_data, RidgeAlpha, LassoAlpha, ElasticNetAlpha):\n    all_data = pd.get_dummies(all_data).reset_index(drop=True)\n    ## Add robust Scaler\n    scaler = RobustScaler()\n    all_data = scaler.fit_transform(all_data)\n    all_data = pd.DataFrame(all_data)\n    X_train = all_data[:train_df.shape[0]]\n    X_test = all_data[train_df.shape[0]:]\n    y = target\n\n    #set up models\n    ridge_model= Ridge(alpha=RidgeAlpha, random_state=42)\n    lasso_model = Lasso(alpha=LassoAlpha, random_state=42)\n    elasticnet_model = ElasticNet(alpha=ElasticNetAlpha, random_state=42)\n\n    #fit the data\n    ridge_model.fit(X_train, y)\n    lasso_model.fit(X_train, y)\n    elasticnet_model.fit(X_train, y)\n\n    #blend models and get predictions\n    # while the coefficients of blending should ideally be done by a gridsearch, there was insufficent time for this\n    def blend_models_predict(X):\n        return ((0.1 * elasticnet_model.predict(X)) + \\\n                (0.2 * lasso_model.predict(X)) + \\\n                (0.7 * ridge_model.predict(X)))\n    # get final predictions from the blended model\n    blended_score = rmsle(y, blend_models_predict(X_train))\n    print('RMSLE score on train data:')\n    print(blended_score)\n\n    # turn to .csv file\n    y_pred = np.floor(np.expm1(blend_models_predict(X_test)))\n    solution = pd.DataFrame({\"id\":id_num, \"SalePrice\":y_pred})\n    solution.to_csv(\"blended.csv\", index = False)","metadata":{"execution":{"iopub.status.busy":"2023-05-08T01:06:13.785838Z","iopub.execute_input":"2023-05-08T01:06:13.786856Z","iopub.status.idle":"2023-05-08T01:06:13.800177Z","shell.execute_reply.started":"2023-05-08T01:06:13.786820Z","shell.execute_reply":"2023-05-08T01:06:13.798855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"section-two-d\"></a>\n## **Function to run all models**\nThis function can be called throughout the data processing and feature selection stage, to check if the feature engineering improves or deprecates the training model. ","metadata":{}},{"cell_type":"code","source":"# defining array to store RMSE scores\nrmse_results =[]","metadata":{"execution":{"iopub.status.busy":"2023-05-08T01:06:13.801798Z","iopub.execute_input":"2023-05-08T01:06:13.802649Z","iopub.status.idle":"2023-05-08T01:06:13.809379Z","shell.execute_reply.started":"2023-05-08T01:06:13.802611Z","shell.execute_reply":"2023-05-08T01:06:13.808417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run_models(df, target, rmse_results):\n    df = pd.get_dummies(df)\n    X_train = df[:train_df.shape[0]]\n    X_testFinal = df[train_df.shape[0]:]\n    X_train, X_test, t_train, t_test = sklearn.model_selection.train_test_split(X_train, target, test_size=0.2, random_state=2)\n    rmse_linear = linear_regression(X_train,X_test, t_train, t_test)\n    rmse_knn = knn(X_train,X_test, t_train, t_test)\n    rmse_r_forest = random_forest_regression(X_train,X_test, t_train, t_test)\n    rmse_linear_ridge = ridge_model(X_train, t_train, X_test, t_test, [0.0001, 0.01, 0.05, 0.1, 0.5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20, 50, 100])\n    rmse_linear_lasso =lasso_model(X_train, t_train, X_test, t_test, [0.0001, 0.01, 0.05, 0.1, 0.5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20, 50, 100])\n   \n    new_column = [rmse_linear, rmse_knn, rmse_r_forest, rmse_linear_ridge, rmse_linear_lasso]\n    rmse_results.append(new_column)\n    return rmse_results","metadata":{"execution":{"iopub.status.busy":"2023-05-08T01:06:13.810759Z","iopub.execute_input":"2023-05-08T01:06:13.811576Z","iopub.status.idle":"2023-05-08T01:06:13.822321Z","shell.execute_reply.started":"2023-05-08T01:06:13.811539Z","shell.execute_reply":"2023-05-08T01:06:13.821029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"section-three\"></a>\n# **3. Data Processing**","metadata":{}},{"cell_type":"markdown","source":"<a id=\"section-three-a\"></a>\n## **Organising Data**\n\nThe data in the DataFrames can be broadly categorised by being:\n\n1. Continuous \n2. Ordinal\n3. Nominal\n\nContinuous data is defined by values that can take on any value within a range, usually numeric information, like area. Ordinal data can be ordered based on some categorical criteria, but the differences between values are not necessarily equal, however, nominal data is data that is categorical and does not have an inherent order or ranking. The way that data is handled and evaluated changes depending on how it is categorised. Therefore, it is recommended that the dataset is organised based on the abovementioned categories.","metadata":{}},{"cell_type":"code","source":"# create DataFrame of categorical data\nnominal = train_df.select_dtypes(include=['object'])","metadata":{"execution":{"iopub.status.busy":"2023-05-08T01:06:13.824217Z","iopub.execute_input":"2023-05-08T01:06:13.824749Z","iopub.status.idle":"2023-05-08T01:06:13.836601Z","shell.execute_reply.started":"2023-05-08T01:06:13.824711Z","shell.execute_reply":"2023-05-08T01:06:13.835516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Thereafter, ordinal data is can usually take on discrete values, usually much smaller than the amount of samples in a dataset (unlike continuous data). Thus, a function that compares whether unique numeric values in a feature are less than a reasonable percentage of the total amount of samples is able to roughly estimate what is categorised by ordinal and continuous data. Any features with unique values less than 5% of the amount of samples is assumed to be ordinal. This is a rough categorization that makes it easier to classify, so it will be fine tuned later on.","metadata":{}},{"cell_type":"code","source":"# categories can also be discrete numeric values\n\n# function that gets a rough estimate of discrete data\ndef get_discrete_data(df, threshold_percent=5):\n    discrete_df = pd.DataFrame()\n    \n    for col in df.columns:\n        if df[col].dtype != 'object':\n            num_unique = df[col].nunique()\n            num_total = len(df[col])\n            percent_unique = (num_unique / num_total) * 100\n\n            if percent_unique <= threshold_percent:\n                discrete_df[col] = df[col]\n            \n    return discrete_df","metadata":{"execution":{"iopub.status.busy":"2023-05-08T01:06:13.838319Z","iopub.execute_input":"2023-05-08T01:06:13.838703Z","iopub.status.idle":"2023-05-08T01:06:13.845489Z","shell.execute_reply.started":"2023-05-08T01:06:13.838668Z","shell.execute_reply":"2023-05-08T01:06:13.844520Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# finding discrete numeric categories using a threshold of 5%\nordinal = get_discrete_data(train_df)","metadata":{"execution":{"iopub.status.busy":"2023-05-08T01:06:13.846892Z","iopub.execute_input":"2023-05-08T01:06:13.847672Z","iopub.status.idle":"2023-05-08T01:06:13.875874Z","shell.execute_reply.started":"2023-05-08T01:06:13.847627Z","shell.execute_reply":"2023-05-08T01:06:13.874657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create DataFrame of continuous data\ncontinuous = train_df[[col for col in train_df.columns if col not in nominal.columns and col not in ordinal.columns]]","metadata":{"execution":{"iopub.status.busy":"2023-05-08T01:06:13.877260Z","iopub.execute_input":"2023-05-08T01:06:13.877633Z","iopub.status.idle":"2023-05-08T01:06:13.884793Z","shell.execute_reply.started":"2023-05-08T01:06:13.877599Z","shell.execute_reply":"2023-05-08T01:06:13.883437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"section-three-a-1\"></a>\n## Initial separation into Continuous, Ordinal and Nominal","metadata":{}},{"cell_type":"code","source":"pd.set_option('display.max_rows', None)\nprint('\\nINITIAL SEPARATION\\n')\nprint('Ordinal\\n', list(set(ordinal.columns)), '\\n')\nprint('Nominal\\n', list(set(nominal.columns)), '\\n')\nprint('Continuous\\n', list(set(continuous.columns)))\npd.set_option('display.max_rows', 10)","metadata":{"execution":{"iopub.status.busy":"2023-05-08T01:06:13.895109Z","iopub.execute_input":"2023-05-08T01:06:13.895617Z","iopub.status.idle":"2023-05-08T01:06:13.903534Z","shell.execute_reply.started":"2023-05-08T01:06:13.895578Z","shell.execute_reply":"2023-05-08T01:06:13.901995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It was found that the 'LowQualFinSF', '3SsnPorch', 'PoolArea', and 'MiscVal' features were incorrectly categorised as ordinal instaed of continuous. While all can take on any value in a range, it was typically miscategorised because they describe instances where are many 0 values in the data. They are reallocated as:","metadata":{}},{"cell_type":"code","source":"# Some continuous data left in 'ordinal_categories'\ncontinuous = continuous.join(ordinal[['LowQualFinSF', '3SsnPorch', 'PoolArea', 'MiscVal']])\nordinal.drop(columns = ['LowQualFinSF','3SsnPorch','PoolArea','MiscVal'], inplace = True)","metadata":{"execution":{"iopub.status.busy":"2023-05-08T01:06:13.904926Z","iopub.execute_input":"2023-05-08T01:06:13.905251Z","iopub.status.idle":"2023-05-08T01:06:13.920096Z","shell.execute_reply.started":"2023-05-08T01:06:13.905220Z","shell.execute_reply":"2023-05-08T01:06:13.919140Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The misorganising of 'YearBuilt', and 'GarageYrBlt' were due to the fact that, while can only take on discrete values, there are many bin values that  data can take on. They are reallocated as:","metadata":{}},{"cell_type":"code","source":"# Some discrete data left in 'continuous'\nordinal = ordinal.join(continuous[['YearBuilt', 'GarageYrBlt']])\ncontinuous.drop(columns = ['YearBuilt', 'GarageYrBlt'], inplace = True)","metadata":{"execution":{"iopub.status.busy":"2023-05-08T01:06:13.921653Z","iopub.execute_input":"2023-05-08T01:06:13.922721Z","iopub.status.idle":"2023-05-08T01:06:13.933528Z","shell.execute_reply.started":"2023-05-08T01:06:13.922669Z","shell.execute_reply":"2023-05-08T01:06:13.932186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Some nominal data left in 'ordinal_categories'\nnominal = nominal.join(ordinal[['MSSubClass']])\nordinal.drop(columns = ['MSSubClass'], inplace = True)","metadata":{"execution":{"iopub.status.busy":"2023-05-08T01:06:13.934913Z","iopub.execute_input":"2023-05-08T01:06:13.935438Z","iopub.status.idle":"2023-05-08T01:06:13.946400Z","shell.execute_reply.started":"2023-05-08T01:06:13.935386Z","shell.execute_reply":"2023-05-08T01:06:13.945306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"section-three-a-2\"></a>\n## Final separation","metadata":{}},{"cell_type":"code","source":"# format tables\nordinal.sort_index(axis = 1, inplace=True)\nnominal.sort_index(axis = 1, inplace=True)\ncontinuous.sort_index(axis = 1, inplace=True)\n\npd.set_option('display.max_rows', None)\nprint('\\nFINAL SEPARATION\\n')\nprint('Ordinal\\n', list(set(ordinal.columns)), '\\n')\nprint('Nominal\\n', list(set(nominal.columns)), '\\n')\nprint('Continuous\\n', list(set(continuous.columns)))","metadata":{"execution":{"iopub.status.busy":"2023-05-08T01:06:13.947797Z","iopub.execute_input":"2023-05-08T01:06:13.948125Z","iopub.status.idle":"2023-05-08T01:06:13.957994Z","shell.execute_reply.started":"2023-05-08T01:06:13.948085Z","shell.execute_reply":"2023-05-08T01:06:13.957011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"section-three-b\"></a>\n## **Combining Train and Test datasets**\nThe two datasets were combined so that data processing does not have to be repeated twice. This is also to prevent data leakage which occurs when informaiton from the test set is inadvertently used to influence model training. If feature selection is performed separately on the training and test datasets, the model may learn patterns that are unique to the training data but are not applicable to the test. This would result in a worse algorithim. In addition if the feature selection picked up on patterns only present in the test data this would not be an accurate reflection on how good the algorithim is.","metadata":{}},{"cell_type":"code","source":"all_data = pd.concat([train_df, test_df], axis=0, sort=False)\nall_data = all_data.reset_index(drop=True)\nall_data['MSSubClass'] = all_data['MSSubClass'].astype(str)\nall_data.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-08T01:06:13.959021Z","iopub.execute_input":"2023-05-08T01:06:13.959901Z","iopub.status.idle":"2023-05-08T01:06:13.995623Z","shell.execute_reply.started":"2023-05-08T01:06:13.959847Z","shell.execute_reply":"2023-05-08T01:06:13.994443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"section-three-c\"></a>\n## **Finding Inter-Feature Dependencies**","metadata":{}},{"cell_type":"code","source":"all_data = all_data.replace(\"None\", np.nan)","metadata":{"execution":{"iopub.status.busy":"2023-05-08T01:06:13.997255Z","iopub.execute_input":"2023-05-08T01:06:13.997749Z","iopub.status.idle":"2023-05-08T01:06:14.016479Z","shell.execute_reply.started":"2023-05-08T01:06:13.997697Z","shell.execute_reply":"2023-05-08T01:06:14.015408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Identifying and Removing Dependent Columns\n\nThe following code block aims to identify and remove columns that are dependent on each other. Keeping dependent columns in the dataset may lead to multicollinearity and adversely affect the performance of regression models.\n\n1. **Estimating Dependent Columns**: We first create an empty DataFrame to store column pairs and their dependency percentages. We then iterate through each column and compare it to all other columns, calculating the percentage of rows in which both columns have zero or NaN values. We store these percentages in the `dependent_df` DataFrame.\n\n2. **Setting a Dependency Threshold**: We set a dependency threshold of 0.99, which means we will consider columns to be dependent if they have a dependency percentage greater than this threshold.\n\n3. **Filtering Dependent Columns**: We filter the `dependent_df` DataFrame to keep only the column pairs with a dependency percentage greater than the threshold. We then store these column pairs in a list called `dependent_columns`.\n\n4. **Dropping Dependent Columns**: The `drop_dependent_cols()` function takes a list of columns to drop as an input. It iterates through each of these columns, and for each column, it finds and removes its dependent columns (with a dependency percentage greater than 0.98) from the dataset.\n\nBy removing dependent columns, we reduce multicollinearity, which improves the stability and performance of our regression models.","metadata":{}},{"cell_type":"code","source":"# find estimate of columns that are dependant on eachother\ndependent_df = pd.DataFrame(columns=['Column 1', 'Column 2', 'Percentage'])\n\n# loop through each column and compare to all other columns\nfor i, col1 in enumerate(all_data.columns):\n    for j, col2 in enumerate(all_data.columns[i+1:], start=i+1):\n        col1_zero_or_nan = (all_data[col1] == 0) | all_data[col1].isna()\n        col2_zero_or_nan = (all_data[col2] == 0) | all_data[col2].isna()\n        both_zeros_or_nan = col1_zero_or_nan & col2_zero_or_nan\n        either_zero_or_nan = col1_zero_or_nan | col2_zero_or_nan\n        percentage = both_zeros_or_nan.sum() / either_zero_or_nan.sum()\n        dependent_df = dependent_df.append({'Column 1': col1, 'Column 2': col2, 'Percentage': percentage}, ignore_index=True)\n\n# set a threshold for dependent columns\ndependency_threshold = 0.99\ndependent_df = dependent_df[dependent_df['Percentage'] > dependency_threshold]\ndependent_columns = dependent_df[['Column 1', 'Column 2']].values.tolist()\ndependent_df","metadata":{"execution":{"iopub.status.busy":"2023-05-08T01:06:14.018049Z","iopub.execute_input":"2023-05-08T01:06:14.019154Z","iopub.status.idle":"2023-05-08T01:06:25.371009Z","shell.execute_reply.started":"2023-05-08T01:06:14.019117Z","shell.execute_reply":"2023-05-08T01:06:25.369738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def drop_dependent_cols(columns_to_drop):\n    # find columns that are dependent on columns_to_drop and add them to columns_to_drop\n    for col in columns_to_drop:\n        dependent_cols = dependent_df[(dependent_df['Column 1'] == col) | (dependent_df['Column 2'] == col)]\n        for index, row in dependent_cols.iterrows():\n            if row['Percentage'] > 0.98:\n                if row['Column 1'] not in columns_to_drop:\n                    columns_to_drop.append(row['Column 1'])\n                    dependent_cols = dependent_cols.drop(index)\n                if row['Column 2'] not in columns_to_drop:\n                    columns_to_drop.append(row['Column 2'])\n                    dependent_cols = dependent_cols.drop(index)\n    return columns_to_drop","metadata":{"execution":{"iopub.status.busy":"2023-05-08T01:06:25.372488Z","iopub.execute_input":"2023-05-08T01:06:25.373339Z","iopub.status.idle":"2023-05-08T01:06:25.380208Z","shell.execute_reply.started":"2023-05-08T01:06:25.373301Z","shell.execute_reply":"2023-05-08T01:06:25.379296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"section-three-d\"></a>\n## **Null Data Handling**","metadata":{}},{"cell_type":"markdown","source":"<a id=\"section-three-d-1\"></a>\n## Finding features that contain null values","metadata":{}},{"cell_type":"code","source":"def get_missing_data(df):\n    missing_amount = df.isnull().sum().sort_values(ascending=False)\n    missing_percent = (df.isnull().sum() / df.isnull().count()).sort_values(ascending=False)\n\n    missing_percent.replace(0, np.nan, inplace=True)\n    missing_percent.dropna(axis=0, inplace=True)\n    missing_percent.sort_values(axis=0, ascending=False, inplace=True)\n\n    missing_amount.replace(0, np.nan, inplace=True)\n    missing_amount.dropna(axis=0, inplace=True)\n    missing_amount.sort_values(axis=0, ascending=False, inplace=True)\n    missing_amount = missing_amount.astype(int)\n\n    missing_data = pd.concat([missing_amount, 100*missing_percent], axis=1, keys=['Amount Missing', 'Percent of total'])\n    \n    return missing_data\n\nmissing_data = get_missing_data(all_data)\nmissing_data","metadata":{"execution":{"iopub.status.busy":"2023-05-08T01:06:25.382335Z","iopub.execute_input":"2023-05-08T01:06:25.382788Z","iopub.status.idle":"2023-05-08T01:06:25.472688Z","shell.execute_reply.started":"2023-05-08T01:06:25.382752Z","shell.execute_reply":"2023-05-08T01:06:25.471413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"section-three-d-2\"></a>\n## Amending errors","metadata":{}},{"cell_type":"code","source":"# Find missing values for MasVnrArea and MasVnrType\n# boolean condition for filtering\ncond = (all_data['MasVnrType'].isna() | (all_data['MasVnrType'] == 0)) ^ (all_data['MasVnrArea'].isna() | (all_data['MasVnrArea'] == 0))\n# filter the DataFrame\nfiltered_data = all_data[cond]\nfiltered_data[['MasVnrType','MasVnrArea']]","metadata":{"execution":{"iopub.status.busy":"2023-05-08T01:06:25.474452Z","iopub.execute_input":"2023-05-08T01:06:25.477717Z","iopub.status.idle":"2023-05-08T01:06:25.498105Z","shell.execute_reply.started":"2023-05-08T01:06:25.477675Z","shell.execute_reply":"2023-05-08T01:06:25.497013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Impute MasVnrArea and MasVnrType values\n\n# Calculate mean MasVnrArea for each non-missing MasVnrType\nmean_areas = all_data.groupby('MasVnrType')['MasVnrArea'].mean()\n\n# Iterate over filtered_data and impute missing values\nfor i, row in filtered_data.iterrows():\n    if pd.isna(row['MasVnrType']):\n        if all_data.loc[i, 'MasVnrArea'] < 10:\n            all_data.loc[i, 'MasVnrArea'] = 0.0\n        else:\n            # Find non-missing MasVnrType with closest mean MasVnrArea to missing MasVnrArea\n            closest_type = mean_areas.index[(mean_areas - row['MasVnrArea']).abs().argmin()]\n            # Fill in closest_type for MasVnrType\n            all_data.loc[i, 'MasVnrType'] = closest_type\n    else:\n        # Fill in mean MasVnrArea for corresponding non-missing MasVnrType\n        all_data.loc[i, 'MasVnrArea'] = mean_areas[row['MasVnrType']]\n\nall_data.loc[filtered_data.index.tolist()][['MasVnrType','MasVnrArea']]","metadata":{"execution":{"iopub.status.busy":"2023-05-08T01:06:25.499394Z","iopub.execute_input":"2023-05-08T01:06:25.499757Z","iopub.status.idle":"2023-05-08T01:06:25.529235Z","shell.execute_reply.started":"2023-05-08T01:06:25.499723Z","shell.execute_reply":"2023-05-08T01:06:25.528074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Find missing values for Garages\n# Find rows where any column containing \"Garage\" is populated, but not all columns are populated\ngarage_cols = [col for col in all_data.columns if 'Garage' in col]\ncond = ((all_data[garage_cols].notnull().any(axis=1) | (all_data[garage_cols] != 0).any(axis=1))\n        & (all_data[garage_cols].isnull().any(axis=1) | (all_data[garage_cols] == 0).any(axis=1))\n        & (all_data[garage_cols][(all_data[garage_cols] != 0) & (all_data[garage_cols].notnull())].any(axis=1)))\n\n# filter the DataFrame\nfiltered_data = all_data[cond]\n# display columns whose names contain 'Garage' for filtered_data\nfiltered_data[filtered_data.filter(like='Garage').columns.tolist()]","metadata":{"execution":{"iopub.status.busy":"2023-05-08T01:06:25.530947Z","iopub.execute_input":"2023-05-08T01:06:25.531306Z","iopub.status.idle":"2023-05-08T01:06:25.571939Z","shell.execute_reply.started":"2023-05-08T01:06:25.531272Z","shell.execute_reply":"2023-05-08T01:06:25.570533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_data.at[2126, 'GarageYrBlt'] = all_data.at[2126, 'YearBuilt']\nall_data.at[2126, 'GarageFinish'] = 'Unf'\nall_data.groupby('OverallQual')['GarageQual'].apply(lambda x: x.mode()[0])\n\n# Remove GarageType in 2576\nall_data.loc[2576, 'GarageType'] = np.nan\n\nall_data.loc[filtered_data.index.tolist()][all_data.filter(like='Garage').columns.tolist()]","metadata":{"execution":{"iopub.status.busy":"2023-05-08T01:06:25.573474Z","iopub.execute_input":"2023-05-08T01:06:25.573844Z","iopub.status.idle":"2023-05-08T01:06:25.600320Z","shell.execute_reply.started":"2023-05-08T01:06:25.573809Z","shell.execute_reply":"2023-05-08T01:06:25.598920Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"section-three-d-3\"></a>\n## Replacing with suitable values\n\nInspired by work done [in this notebook](https://www.kaggle.com/code/ruthannwright/1-house-prices-solution-top-1/edit)\n","metadata":{}},{"cell_type":"markdown","source":"The following code fills in the missing values for the MSZoning column based on the MSSubClass's mode for MSZoning. And the LotFrontage is also filled in by the mode for the Neighborhood data.  ","metadata":{}},{"cell_type":"code","source":"all_data['MSZoning'] = all_data.groupby('MSSubClass')['MSZoning'].transform(lambda x: x.fillna(x.mode()[0]))","metadata":{"execution":{"iopub.status.busy":"2023-05-08T01:06:25.601661Z","iopub.execute_input":"2023-05-08T01:06:25.602680Z","iopub.status.idle":"2023-05-08T01:06:25.620266Z","shell.execute_reply.started":"2023-05-08T01:06:25.602638Z","shell.execute_reply":"2023-05-08T01:06:25.619160Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The following data processing was done after carefully examining the dataset. In some cases any missing data should be relaced as 'typical functinality.' Example for the Functional data replace with 'Typ' or Kitchen Quality with 'TA.' Electrical is replaced with the mode as there is no typical value for it and as is it not numeric, a median will not work. ","metadata":{}},{"cell_type":"code","source":"# Impute missing Functional data\nall_data['Functional'] = all_data['Functional'].fillna('Typ')\n# Impute missing Electrical data\nall_data['Electrical'].fillna(all_data['Electrical'].mode()[0], inplace = True)\n# Impute missing KitchenQual data\nall_data['KitchenQual'] = all_data['KitchenQual'].fillna(\"TA\")","metadata":{"execution":{"iopub.status.busy":"2023-05-08T01:06:25.621646Z","iopub.execute_input":"2023-05-08T01:06:25.621996Z","iopub.status.idle":"2023-05-08T01:06:25.631106Z","shell.execute_reply.started":"2023-05-08T01:06:25.621961Z","shell.execute_reply":"2023-05-08T01:06:25.629713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"More missing data values are then filled in with the mode for ordinal data categories ","metadata":{}},{"cell_type":"code","source":"# Impute missing Exterior1st data\nall_data['Exterior1st'] = all_data['Exterior1st'].fillna(all_data['Exterior1st'].mode()[0])\n# Impute missing Exterior2nd data\nall_data['Exterior2nd'] = all_data['Exterior2nd'].fillna(all_data['Exterior2nd'].mode()[0])\n# Impute missing SaleType data\nall_data['SaleType'] = all_data['SaleType'].fillna(all_data['SaleType'].mode()[0])","metadata":{"execution":{"iopub.status.busy":"2023-05-08T01:06:25.632557Z","iopub.execute_input":"2023-05-08T01:06:25.632907Z","iopub.status.idle":"2023-05-08T01:06:25.644958Z","shell.execute_reply.started":"2023-05-08T01:06:25.632873Z","shell.execute_reply":"2023-05-08T01:06:25.643873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_missing_data(all_data)","metadata":{"execution":{"iopub.status.busy":"2023-05-08T01:06:25.646278Z","iopub.execute_input":"2023-05-08T01:06:25.647158Z","iopub.status.idle":"2023-05-08T01:06:25.689794Z","shell.execute_reply.started":"2023-05-08T01:06:25.647120Z","shell.execute_reply":"2023-05-08T01:06:25.687802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As the above table shows, there are still missing values in the code. Here a more generic approcah is taken to deal with the remaining missing data values. If the data is cateogrical (is of type object) then the missing data is filled by 'None'\nFor any data that takes on a numerica values, the missing data is filled with 0.  ","metadata":{}},{"cell_type":"code","source":"objects = []\nfor i in all_data.columns:\n    if all_data[i].dtype == object:\n        objects.append(i)\nall_data.update(all_data[objects].fillna('None'))\n\nall_data['LotFrontage'] = all_data.groupby('Neighborhood')['LotFrontage'].transform(lambda x: x.fillna(x.median()))\n\n\nnumeric_dtypes = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\nnumerics = []\nfor i in all_data.columns:\n    if all_data[i].dtype in numeric_dtypes:\n        numerics.append(i)\nall_data.update(all_data[numerics].fillna(0))","metadata":{"execution":{"iopub.status.busy":"2023-05-08T01:06:25.691676Z","iopub.execute_input":"2023-05-08T01:06:25.692849Z","iopub.status.idle":"2023-05-08T01:06:25.810520Z","shell.execute_reply.started":"2023-05-08T01:06:25.692794Z","shell.execute_reply":"2023-05-08T01:06:25.809232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_missing_data(all_data)","metadata":{"execution":{"iopub.status.busy":"2023-05-08T01:06:25.812241Z","iopub.execute_input":"2023-05-08T01:06:25.813045Z","iopub.status.idle":"2023-05-08T01:06:25.852176Z","shell.execute_reply.started":"2023-05-08T01:06:25.812995Z","shell.execute_reply":"2023-05-08T01:06:25.850759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"section-three-e\"></a>\n## **Running models before feature selection**","metadata":{}},{"cell_type":"code","source":"rmse_results = run_models(all_data, target, rmse_results)","metadata":{"execution":{"iopub.status.busy":"2023-05-08T01:06:25.853795Z","iopub.execute_input":"2023-05-08T01:06:25.854181Z","iopub.status.idle":"2023-05-08T01:07:14.207637Z","shell.execute_reply.started":"2023-05-08T01:06:25.854144Z","shell.execute_reply":"2023-05-08T01:07:14.206652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"section-four\"></a>\n# **4. Feature Selection**\nInspired by work done [in this notebook](https://github.com/carlosfarfangalindoNL222/Learning-Machine-Learning-with-House_Prices_Challenge/blob/main/Code/House_Price_newest.ipynb)","metadata":{}},{"cell_type":"markdown","source":"<a id=\"section-four-a\"></a>\n## **Fix the Skewness of the Data**\nFixing skewness by taking the log of numerical data helps to reduce the impact of outliers and helps to normalize the data for better model performance. ","metadata":{}},{"cell_type":"code","source":"from scipy.stats import skew\n#log transform skewed numeric features:\ntarget= np.log1p(target)\n\nnumeric_feats = all_data.dtypes[all_data.dtypes != \"object\"].index #get the index of all the numeric features\n\nskewed_feats = all_data[numeric_feats].apply(lambda x: skew(x.dropna())) #compute skewness\n\nskewed_feats = skewed_feats[skewed_feats > 0.75] #get the features that are skewed\nskewed_feats = skewed_feats.index\n\nall_data[skewed_feats] = np.log1p(all_data[skewed_feats])","metadata":{"execution":{"iopub.status.busy":"2023-05-08T01:07:14.209428Z","iopub.execute_input":"2023-05-08T01:07:14.210061Z","iopub.status.idle":"2023-05-08T01:07:14.241212Z","shell.execute_reply.started":"2023-05-08T01:07:14.210021Z","shell.execute_reply":"2023-05-08T01:07:14.240312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rmse_results = run_models(all_data, target, rmse_results)","metadata":{"execution":{"iopub.status.busy":"2023-05-08T01:07:14.242696Z","iopub.execute_input":"2023-05-08T01:07:14.243309Z","iopub.status.idle":"2023-05-08T01:07:55.804654Z","shell.execute_reply.started":"2023-05-08T01:07:14.243272Z","shell.execute_reply":"2023-05-08T01:07:55.803370Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"section-four-b\"></a>\n## **Filtering high-NaN features**\nRemove columns with above 85% null values. This improves the data quality as columns with a large proportion of missing values may indicate poor data quality, and including them in the analysis can potentially introduce bias or noise into the results.It also helps improve the computational efficiency of the code and will hopefully improve the model's performance. ","metadata":{}},{"cell_type":"code","source":"# find columns to drop based on percentage of missing data\nmissing_data.dropna(inplace=True)\nmissing_data = missing_data[missing_data['Percent of total'] > 85]\ncolumns_to_drop = missing_data.index.tolist()\ncolumns_to_drop = drop_dependent_cols(columns_to_drop)\n\nall_data = all_data.drop(columns_to_drop, axis=1)\nprint(f\"Dropped {columns_to_drop}.\")\nprint(f\"\\nRemaining columns: {len(all_data.columns.tolist())}\\n\")\nall_data.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-08T01:07:55.806616Z","iopub.execute_input":"2023-05-08T01:07:55.810123Z","iopub.status.idle":"2023-05-08T01:07:55.832881Z","shell.execute_reply.started":"2023-05-08T01:07:55.810067Z","shell.execute_reply":"2023-05-08T01:07:55.831582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rmse_results = run_models(all_data, target, rmse_results)","metadata":{"execution":{"iopub.status.busy":"2023-05-08T01:07:55.834436Z","iopub.execute_input":"2023-05-08T01:07:55.834796Z","iopub.status.idle":"2023-05-08T01:08:37.395302Z","shell.execute_reply.started":"2023-05-08T01:07:55.834759Z","shell.execute_reply":"2023-05-08T01:08:37.394383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"section-four-d-1\"></a>\n## Adding novel features\nAdding new feautres can provide new insight and additional information to the model. It allows for new complex relationships between the data and the target variable to be discovered. However, one does run the risk of adding too many features by adding noise and overfitting. \n\nThe new features added combine features that are linked to each other, by adding new columns for total square footage, total number of batherooms. It then also adds some boolean columns stating if a feature is present or not. This adds more clarity about certain features. \n","metadata":{}},{"cell_type":"code","source":"all_data['TotalSF'] = all_data['TotalBsmtSF'] + all_data['1stFlrSF'] + all_data['2ndFlrSF']\nall_data['TotalBathrooms'] = (all_data['FullBath'] + (0.5 * all_data['HalfBath']) + all_data['BsmtFullBath'] + (0.5 * all_data['BsmtHalfBath']))\nall_data['TotalPorchSF'] = (all_data['OpenPorchSF'] + all_data['3SsnPorch'] + all_data['EnclosedPorch'] + all_data['ScreenPorch'] + all_data['WoodDeckSF'])\n\nall_data['Has2ndFloor'] = all_data['2ndFlrSF'].apply(lambda x: 1 if x > 0 else 0)\nall_data['HasGarage'] = all_data['GarageArea'].apply(lambda x: 1 if x > 0 else 0)\nall_data['HasBsmt'] = all_data['TotalBsmtSF'].apply(lambda x: 1 if x > 0 else 0)\nall_data['HasFireplace'] = all_data['Fireplaces'].apply(lambda x: 1 if x > 0 else 0)","metadata":{"execution":{"iopub.status.busy":"2023-05-08T01:08:37.396541Z","iopub.execute_input":"2023-05-08T01:08:37.397462Z","iopub.status.idle":"2023-05-08T01:08:37.421178Z","shell.execute_reply.started":"2023-05-08T01:08:37.397425Z","shell.execute_reply":"2023-05-08T01:08:37.420222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_data.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-08T01:08:37.423079Z","iopub.execute_input":"2023-05-08T01:08:37.423554Z","iopub.status.idle":"2023-05-08T01:08:37.454115Z","shell.execute_reply.started":"2023-05-08T01:08:37.423507Z","shell.execute_reply":"2023-05-08T01:08:37.452937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rmse_results = run_models(all_data, target, rmse_results)","metadata":{"execution":{"iopub.status.busy":"2023-05-08T01:08:37.455667Z","iopub.execute_input":"2023-05-08T01:08:37.456082Z","iopub.status.idle":"2023-05-08T01:09:16.693132Z","shell.execute_reply.started":"2023-05-08T01:08:37.456046Z","shell.execute_reply":"2023-05-08T01:09:16.691910Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Calling Linear Regularization Model\nAt this point the Lasso and Ridge RMSE are minimal, further reducing the number of features does not improve their scores. Therefore, this is where more indepth linear regularization needs to take place. This includes using grid search, elasticnet and then using a combination of them. RobustScaler is also used which imroves the result. ","metadata":{}},{"cell_type":"code","source":"rmse_results = run_models(all_data, target, rmse_results)","metadata":{"execution":{"iopub.status.busy":"2023-05-08T01:13:08.353387Z","iopub.execute_input":"2023-05-08T01:13:08.353977Z","iopub.status.idle":"2023-05-08T01:13:44.119113Z","shell.execute_reply.started":"2023-05-08T01:13:08.353925Z","shell.execute_reply":"2023-05-08T01:13:44.117825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Linear_Regularization_With_RobustScaler(all_data)","metadata":{"execution":{"iopub.status.busy":"2023-05-08T01:12:50.149106Z","iopub.execute_input":"2023-05-08T01:12:50.149486Z","iopub.status.idle":"2023-05-08T01:12:58.853064Z","shell.execute_reply.started":"2023-05-08T01:12:50.149449Z","shell.execute_reply":"2023-05-08T01:12:58.851767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Linear_Regularization(all_data)","metadata":{"execution":{"iopub.status.busy":"2023-05-08T01:09:16.694665Z","iopub.execute_input":"2023-05-08T01:09:16.695011Z","iopub.status.idle":"2023-05-08T01:12:50.147674Z","shell.execute_reply.started":"2023-05-08T01:09:16.694978Z","shell.execute_reply":"2023-05-08T01:12:50.146429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"section-four-c\"></a>\n## **Filtering highly dominated categories**","metadata":{}},{"cell_type":"markdown","source":"<a id=\"section-four-d-2\"></a>\n## Removing legacy features","metadata":{}},{"cell_type":"code","source":"all_data.drop([ 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'FullBath', 'HalfBath', 'BsmtFullBath', 'BsmtHalfBath', \n               'OpenPorchSF', '3SsnPorch', 'EnclosedPorch', 'ScreenPorch', 'WoodDeckSF'], axis=1, inplace=True)\nall_data.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-08T01:13:08.342666Z","iopub.execute_input":"2023-05-08T01:13:08.343282Z","iopub.status.idle":"2023-05-08T01:13:08.352037Z","shell.execute_reply.started":"2023-05-08T01:13:08.343248Z","shell.execute_reply":"2023-05-08T01:13:08.351063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Replacing NaN with 'None'\ncommon_cols = list(set(nominal.columns) & set(all_data.columns))\nall_data[common_cols].replace(np.nan, \"None\", inplace = True) #is this still needed?? \nnr_rows = np.ceil(len(common_cols) / 4).astype(int)\n\n# create subplots of bar plots for nominal data\nfig, axes = plt.subplots(nrows = nr_rows, ncols=4, figsize=(27, 48))\n\n# iterate through each column and create a bar plot\nfor i, col in enumerate(common_cols):\n    # count the number of instances for each category in the column\n    counts = all_data[col].value_counts()\n    # create a bar plot of the category counts\n    colors = plt.cm.tab20(np.arange(len(counts)))\n    counts.plot(kind='bar', ax=axes.flat[i] if i < len(nominal.columns) else None, color=colors)\n    axes.flat[i].set_title(col)\n    axes.flat[i].set_xlabel('Category')\n    axes.flat[i].set_ylabel('Count')\n    # annotate each bar with its count value\n    for j, count in enumerate(counts):\n        axes.flat[i].text(j, count, str(count), ha='center', va='bottom')\n\n# adjust spacing between subplots\nplt.subplots_adjust(wspace=0.3, hspace=0.8)\n\n# show the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-08T01:12:59.243902Z","iopub.execute_input":"2023-05-08T01:12:59.244762Z","iopub.status.idle":"2023-05-08T01:13:08.294693Z","shell.execute_reply.started":"2023-05-08T01:12:59.244714Z","shell.execute_reply":"2023-05-08T01:13:08.293415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# If one category is more than 98% dominant, drop it from all_data\n# create a list to store column names that should be dropped\ncolumns_to_drop = []\n\n# iterate through each column in common_cols\nfor col in common_cols:\n    # count the number of instances for each category in the column\n    counts = all_data[col].value_counts(normalize=True)\n    # check if any category is more than 95% dominant\n    if counts.iloc[0] > 0.98:\n        # if so, add the column name to columns_to_drop\n        columns_to_drop.append(col)\n\n# drop columns_to_drop from all_data\nall_data.drop(columns_to_drop, axis=1, inplace = True)\n\ncommon_cols = list(set(nominal.columns) & set(all_data.columns))\nprint(f\"Dropped {columns_to_drop}.\")\nprint(f\"\\nRemaining nominal columns: {len(all_data[common_cols].columns.tolist())}\\n\")\nall_data.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-08T01:13:08.296244Z","iopub.execute_input":"2023-05-08T01:13:08.296915Z","iopub.status.idle":"2023-05-08T01:13:08.341216Z","shell.execute_reply.started":"2023-05-08T01:13:08.296876Z","shell.execute_reply":"2023-05-08T01:13:08.340409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Linear_Regularization_Solution(all_data, 9.5, 0.008, 0.001)","metadata":{"execution":{"iopub.status.busy":"2023-05-08T01:12:58.854899Z","iopub.execute_input":"2023-05-08T01:12:58.855647Z","iopub.status.idle":"2023-05-08T01:12:59.242046Z","shell.execute_reply.started":"2023-05-08T01:12:58.855599Z","shell.execute_reply":"2023-05-08T01:12:59.240761Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"section-four-e\"></a>\n## **Filtering low-relation features**","metadata":{}},{"cell_type":"markdown","source":"<a id=\"section-four-e-1\"></a>\n## Low relation categories","metadata":{}},{"cell_type":"markdown","source":"## Boxplot Visualization of Categorical Features\n\nWe create a boxplot visualization of the relationship between categorical features and the target variable to gain insights into their distribution and potential outliers. The plot is divided into a grid of 7 rows and 5 columns, each containing a boxplot for one categorical feature.\n\nThe boxplots help us understand how the categorical features relate to the target variable and reveal potential patterns or irregularities. By inspecting these boxplots, we can make informed decisions about feature selection and preprocessing steps.","metadata":{}},{"cell_type":"code","source":"nr_cols = 5\nnr_rows = 7\nfig, axs = plt.subplots(7, 5, figsize=(40,48))\n\nfor r in range(0,nr_rows):\n    for c in range(0,nr_cols):\n        i = r*nr_cols+c\n        if i < len(common_cols):\n            sns.boxplot(x=common_cols[i], y=target, data=all_data, ax = axs[r][c])\n            \nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-08T01:13:44.121206Z","iopub.execute_input":"2023-05-08T01:13:44.121714Z","iopub.status.idle":"2023-05-08T01:13:54.454226Z","shell.execute_reply.started":"2023-05-08T01:13:44.121658Z","shell.execute_reply":"2023-05-08T01:13:54.453306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ANOVA Encoding for Categorical Features\n\nWe use ANOVA (Analysis of Variance) encoding to encode the categorical features. This method encodes categorical features based on the mean of the target variable for each category. It calculates the F-statistic and the associated p-value, which helps us understand the significance of each categorical feature in predicting the target variable.\n\nWe fit the ANOVA encoder on the training dataset and transform the categorical features.\n","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler, OrdinalEncoder\nimport category_encoders as ce\ntrain_temp = all_data[:train_df.shape[0]]\n# Encoding using ANOVA\ncommon_cols = list(set(nominal.columns) & set(all_data.columns))\nencoder = ce.TargetEncoder(train_temp[common_cols])\nencoder.fit(train_temp[common_cols], target_log)\nte = encoder.fit_transform(train_temp[common_cols], target_log)","metadata":{"execution":{"iopub.status.busy":"2023-05-08T01:13:54.455523Z","iopub.execute_input":"2023-05-08T01:13:54.456057Z","iopub.status.idle":"2023-05-08T01:13:55.748202Z","shell.execute_reply.started":"2023-05-08T01:13:54.456022Z","shell.execute_reply":"2023-05-08T01:13:55.746947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_selection import SelectKBest,f_regression \ntarget_log\nanova = SelectKBest(score_func=f_regression, k=30)\nanova.fit_transform(te,target_log)\n\nanova_score = pd.DataFrame({'Anova Score':anova.scores_, 'p-Value': anova.pvalues_}, index=common_cols)\nanova_score.sort_values(by=['p-Value'], ascending=False)","metadata":{"execution":{"iopub.status.busy":"2023-05-08T01:13:55.750007Z","iopub.execute_input":"2023-05-08T01:13:55.751165Z","iopub.status.idle":"2023-05-08T01:13:55.816469Z","shell.execute_reply.started":"2023-05-08T01:13:55.751104Z","shell.execute_reply":"2023-05-08T01:13:55.814872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Selecting Strongly Correlated Categorical Features\n\nUsing the `SelectKBest` function from the `sklearn.feature_selection` module, we select the top 30 categorical features with the highest F-statistic scores. We store these scores and their corresponding p-values in a DataFrame called `anova_score`, sorted in descending order of p-values.\n\nWe then select the categorical features with a p-value less than or equal to 0.01 and an F-statistic score greater than 400 as strongly correlated features. We store these features in a list called `strong_corr_cat`.","metadata":{}},{"cell_type":"code","source":"strong_corr_cat = list(anova_score[(anova_score['p-Value'] <= 0.01) & (anova_score['Anova Score'] > 400)].index)\n\nprint(len(strong_corr_cat))\nprint(strong_corr_cat)\nprint('*'*150)\n\nweak_corr_cat= [col for col in common_cols if col not in strong_corr_cat]\nprint(weak_corr_cat)","metadata":{"execution":{"iopub.status.busy":"2023-05-08T01:13:55.818496Z","iopub.execute_input":"2023-05-08T01:13:55.819228Z","iopub.status.idle":"2023-05-08T01:13:55.830440Z","shell.execute_reply.started":"2023-05-08T01:13:55.819193Z","shell.execute_reply":"2023-05-08T01:13:55.827260Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Identifying and Dropping Weakly Correlated Categorical Features\n\nWe create a list called `columns_to_drop`, which initially contains the weakly correlated categorical features (features not in `strong_corr_cat`). We then use the `drop_dependent_cols()` function to add any dependent columns to this list.\n\nFinally, we drop all the columns in `columns_to_drop` from the dataset and update the `common_cols` list to reflect the remaining nominal columns. This step helps us reduce the dimensionality of our dataset and focus on the most relevant features for our regression models.\n","metadata":{}},{"cell_type":"code","source":"# create a list to store column names that should be dropped\ncolumns_to_drop = []\ncolumns_to_drop = weak_corr_cat\ncolumns_to_drop = drop_dependent_cols(columns_to_drop)\n\nall_data.drop(columns_to_drop, axis = 1, inplace = True)\n\ncommon_cols = list(set(nominal.columns) & set(all_data.columns))\nprint(f\"Dropped {columns_to_drop}.\")\nprint(f\"\\nRemaining nominal columns: {len(all_data[common_cols].columns.tolist())}\\n\")\nall_data.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-08T01:13:55.832021Z","iopub.execute_input":"2023-05-08T01:13:55.833007Z","iopub.status.idle":"2023-05-08T01:13:55.908160Z","shell.execute_reply.started":"2023-05-08T01:13:55.832951Z","shell.execute_reply":"2023-05-08T01:13:55.906857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rmse_results = run_models(all_data, target, rmse_results)","metadata":{"execution":{"iopub.status.busy":"2023-05-08T01:13:55.910054Z","iopub.execute_input":"2023-05-08T01:13:55.910862Z","iopub.status.idle":"2023-05-08T01:14:15.599644Z","shell.execute_reply.started":"2023-05-08T01:13:55.910812Z","shell.execute_reply":"2023-05-08T01:14:15.598322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"section-four-e-2\"></a>\n## Low relation numericals","metadata":{}},{"cell_type":"markdown","source":"## Scatterplots of Numerical Features and Target\n\nWe create scatterplots of the relationship between numerical features (continuous and ordinal) and the target variable to gain insights into their distribution, potential patterns, and outliers. The plot is divided into a grid of 5 rows and 4 columns, each containing a scatterplot for one numerical feature. We also calculate the Pearson correlation coefficient (r) for each feature and display it in the plot title.\n\nThe scatterplots help us understand how the numerical features relate to the target variable and reveal potential linear or non-linear relationships. By inspecting these scatterplots, we can make informed decisions about feature selection and preprocessing steps.","metadata":{}},{"cell_type":"code","source":"plot_row = 5\nplot_col = 4\ntrain_temp = all_data[:train_df.shape[0]]\n\n# create a list to store column names that should be dropped\ncolumns_to_drop = []\n\nfig, axs = plt.subplots(plot_row, plot_col, figsize=(plot_col*3.5,plot_row*3))\n# Create a list of all numerical features\ncommon_cols = list((set(continuous.columns) | set(ordinal.columns)) & set(all_data.columns))\n\ncolors = ['red', 'blue', 'green', 'orange', 'purple', 'gray', 'black', 'brown', 'pink']\n\n# Define threshold for absolute r-values to keep\nr_threshold = 0.1\n\nfor r in range(0,plot_row):\n    for c in range(0,plot_col):\n        sub_plot = r*plot_col+c\n        if sub_plot < len(common_cols):\n            x = train_temp[common_cols[sub_plot]]\n            y = target\n            stp = stats.pearsonr(x, y)\n            sns.regplot(x=x, y=y, color=colors[sub_plot % len(colors)], ax=axs[r][c])\n            str_title = \"r = \" + \"{0:.2f}\".format(stp[0])\n            axs[r][c].set_title(str_title, fontsize=12)\n            if abs(stp[0]) <= r_threshold:\n                columns_to_drop.append(common_cols[sub_plot])\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-08T01:14:15.601320Z","iopub.execute_input":"2023-05-08T01:14:15.601714Z","iopub.status.idle":"2023-05-08T01:14:22.067567Z","shell.execute_reply.started":"2023-05-08T01:14:15.601677Z","shell.execute_reply":"2023-05-08T01:14:22.066286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Identifying and Dropping Weakly Correlated Numerical Features\n\nWe define a threshold for the absolute Pearson correlation coefficient (r-value) of 0.1. If a feature has an absolute r-value below this threshold, we consider it weakly correlated and add it to the `columns_to_drop` list.\n\nWe then remove 'OverallCond' from `columns_to_drop` because it is an important feature that we want to keep. We also use the `drop_dependent_cols()` function to add any dependent columns to this list.\n\nFinally, we drop all the columns in `columns_to_drop` from the dataset and update the `common_cols` list to reflect the remaining numerical columns. This step helps us reduce the dimensionality of our dataset and focus on the most relevant features for our regression models.","metadata":{}},{"cell_type":"code","source":"columns_to_drop.remove('OverallCond')\ncolumns_to_drop = drop_dependent_cols(columns_to_drop)\nall_data.drop(columns_to_drop, axis = 1, inplace = True)\n\ncommon_cols = list((set(continuous.columns) | set(ordinal.columns)) & set(all_data.columns))\nprint(f\"Dropped {columns_to_drop}.\")\nprint(f\"\\nRemaining numerical columns: {len(all_data[common_cols].columns.tolist())}\\n\")\nall_data.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-08T01:14:22.069106Z","iopub.execute_input":"2023-05-08T01:14:22.069527Z","iopub.status.idle":"2023-05-08T01:14:22.086088Z","shell.execute_reply.started":"2023-05-08T01:14:22.069486Z","shell.execute_reply":"2023-05-08T01:14:22.084692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rmse_results = run_models(all_data, target, rmse_results)","metadata":{"execution":{"iopub.status.busy":"2023-05-08T01:14:22.087587Z","iopub.execute_input":"2023-05-08T01:14:22.087971Z","iopub.status.idle":"2023-05-08T01:14:42.098546Z","shell.execute_reply.started":"2023-05-08T01:14:22.087932Z","shell.execute_reply":"2023-05-08T01:14:42.097137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"section-four-f\"></a>\n## **Filtering multicollinear features**","metadata":{}},{"cell_type":"code","source":"# create a list of columns present in both train_data and continuous\ncommon_cols = list(set(all_data.columns) & (set(continuous.columns) | set(ordinal.columns)))\n\n# select only common columns in train_data\ntrain_data_common = all_data[common_cols]\n\n# compute the correlation matrix\nheatmap_data = train_data_common.corr()\n\n# create a mask to only show the lower triangle\nmask = np.zeros_like(heatmap_data, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\n# set up the matplotlib figure\nfig, ax = plt.subplots(figsize=(15, 12))\n\n# create a heatmap\nsns.heatmap(heatmap_data, mask=mask, cmap=\"coolwarm\", annot=True, fmt=\".2f\", linewidths=.05, \n            annot_kws={\"size\": 8}, vmin=-0.5, vmax=0.5, center=0)\n\n# rotate the x-axis labels\nplt.xticks(rotation=90)\n\n# show the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-08T01:14:42.100601Z","iopub.execute_input":"2023-05-08T01:14:42.101900Z","iopub.status.idle":"2023-05-08T01:14:42.940094Z","shell.execute_reply.started":"2023-05-08T01:14:42.101839Z","shell.execute_reply":"2023-05-08T01:14:42.938543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"correlation = all_data[common_cols].corr()\ncorr_threshold = 0.65\nhighly_corr = correlation[(correlation.abs() > corr_threshold) & (correlation != 1)].stack().reset_index()\nhighly_corr.columns = ['Column 1', 'Column 2', 'Correlation']\n\nindex_to_remove = []\n\nhighly_corr.drop(axis=0,index = index_to_remove , inplace =True)\nprint(\"Highly correlated columns:\")\nprint(highly_corr)","metadata":{"execution":{"iopub.status.busy":"2023-05-08T01:14:42.941798Z","iopub.execute_input":"2023-05-08T01:14:42.942257Z","iopub.status.idle":"2023-05-08T01:14:42.963207Z","shell.execute_reply.started":"2023-05-08T01:14:42.942212Z","shell.execute_reply":"2023-05-08T01:14:42.962002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"saleCorrelation = all_data[common_cols].corrwith(target)\n\nless_corr_cols = []\nfor i, row in highly_corr.iterrows():\n    if(saleCorrelation[row[0]]> saleCorrelation[row[1]]):\n        less_corr_cols.append(row[1])\n    else:\n        less_corr_cols.append(row[0])\nprint(\"Columns less correlated to SalePrice:\")\nprint(less_corr_cols)\ncolumns_to_drop = list(set(less_corr_cols))","metadata":{"execution":{"iopub.status.busy":"2023-05-08T01:14:42.964440Z","iopub.execute_input":"2023-05-08T01:14:42.964770Z","iopub.status.idle":"2023-05-08T01:14:42.987913Z","shell.execute_reply.started":"2023-05-08T01:14:42.964738Z","shell.execute_reply":"2023-05-08T01:14:42.986699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"columns_to_drop = drop_dependent_cols(columns_to_drop)\n\nall_data.drop(columns_to_drop, axis = 1, inplace = True)\n\ncommon_cols = list((set(continuous.columns) | set(ordinal.columns)) & set(all_data.columns))\nprint(f\"Dropped {columns_to_drop}.\")\nprint(f\"\\nRemaining numerical columns: {len(all_data[common_cols].columns.tolist())}\\n\")\nall_data.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-08T01:14:42.989650Z","iopub.execute_input":"2023-05-08T01:14:42.990120Z","iopub.status.idle":"2023-05-08T01:14:43.005616Z","shell.execute_reply.started":"2023-05-08T01:14:42.990082Z","shell.execute_reply":"2023-05-08T01:14:43.004412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rmse_results = run_models(all_data, target, rmse_results)","metadata":{"execution":{"iopub.status.busy":"2023-05-08T01:14:43.007702Z","iopub.execute_input":"2023-05-08T01:14:43.008134Z","iopub.status.idle":"2023-05-08T01:15:01.615123Z","shell.execute_reply.started":"2023-05-08T01:14:43.008080Z","shell.execute_reply":"2023-05-08T01:15:01.613773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"section-five\"></a>\n# **5. Results**","metadata":{}},{"cell_type":"code","source":"def plot_RMSE(results):\n\n    array = results\n    # Create a list of x values from 1 to the number of data points\n    x = range(len(array))\n\n    # plot each sublist as a separate line\n    for i in range(len(array[0])):\n        plt.plot(x, [sublist[i] for sublist in array])\n\n    # add legend and axis labels\n    plt.legend(labels=[\"Linear\",\"KNN\",\"Random Forest\", \"Ridge\", \"Lasso\"])\n    plt.xlabel(\"Index\")\n    plt.ylabel(\"Value\")\n    plt.yscale('log') # set y-axis to log scale\n\n    # show plot\n    plt.show()\n\nplot_RMSE(rmse_results)\nprint(rmse_results)","metadata":{"execution":{"iopub.status.busy":"2023-05-08T01:15:01.616650Z","iopub.execute_input":"2023-05-08T01:15:01.616973Z","iopub.status.idle":"2023-05-08T01:15:02.434716Z","shell.execute_reply.started":"2023-05-08T01:15:01.616942Z","shell.execute_reply":"2023-05-08T01:15:02.433506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## In-depth Analysis of Results\n\nThe results contain the RMSE values for each model at different stages of the feature engineering process. The models used are Linear Regression, KNN, Random Forest, Ridge, and Lasso. The feature engineering processes are applied in the following order:\n\n1. No feature selection\n2. Fixing skewness\n3. Filtering high NaN features\n4. Filtering dominant categories\n5. Feature addition and removal of legacy features\n6. Filtering low relation categories and low correlated numerical features\n7. Filtering multicollinear features\n\n### No feature selection\n\nThis is the baseline model with all the features, and it serves as a reference point for the subsequent feature engineering processes. The models have varying RMSE values, with the Random Forest model performing the best and KNN performing the worst.\n\n### Fixing skewness\n\nSkewed features can cause problems for certain models, particularly linear regression models, which assume normality in the distribution of the data. This step involves transforming skewed features to improve the normality of their distributions. Most of the models show an improvement in their RMSE values. The transformation helps the models better capture the relationships between features and the target variable.\n\n### Filtering high NaN features\n\nRemoving features with a high proportion of missing values can reduce noise and dimensionality in the data, allowing models to focus on more relevant features. This step results in a slight improvement for most models, except for KNN, which has a slight increase in RMSE.\n\n### Filtering dominant categories\n\nRemoving features with a dominant category can improve the performance of models that are sensitive to multicollinearity, such as Ridge and Lasso regression models. This step improves the performance of the Ridge and Lasso models, while it slightly worsens the performance of the other models.\n\n### Feature addition and removal of legacy features\n\nThe addition of new features can capture more information about the target variable, while the removal of legacy features can reduce noise and dimensionality. The performance of all models, except KNN, improves after this step. \n\n### Filtering low relation categories and low correlated numerical features\n\nRemoving weakly correlated features helps reduce noise and dimensionality, allowing models to focus on more relevant features. This step improves the performance for most models, except for Ridge, which shows a slight increase in RMSE.\n\n### Filtering multicollinear features\n\nMulticollinear features can cause problems for certain models, particularly linear regression models, which assume that features are independent. Removing multicollinear features has a minor impact on the models' performance, with a slight improvement for most models. This step helps address multicollinearity, which can be particularly beneficial for linear models.\n\n## **Model Evaluation**\n\n| Step | Description                                         | Linear         | KNN            | Random Forest  | Ridge          | Lasso          |\n|------|-----------------------------------------------------|----------------|----------------|----------------|----------------|----------------|\n| 1    | No feature engineering                              | 38062.08       | 47679.64       | 27355.38   | **25657.45**       | 28164.97       |\n| 2    | Fixing skewness                                     | 0.1496     | 0.2626         | 0.1478         | **0.1236**         | 0.1354         |\n| 3    | Filtering high-NaN values                           | 0.1464     | 0.2629         | 0.1495         | **0.1207**         | 0.1360         |\n| 4    | Adding features                                     | 212069.55      | 0.2596         | 0.1509         | **0.1206**         | 0.1362     |\n| 5    | Removing legacy features and Filtering highly-dominant features | 0.1314 | 0.2594 | 0.1473 | **0.1204** | 0.1250         |\n| 6    | Dropping weak-correlated categories                 | 0.1280         | 0.2471         | 0.1485         | 0.1275     | **0.1272**         |\n| 7    | Dropping weak-correlated continuous data            | 0.1272         | 0.2398         | 0.1487         | 0.1266     | **0.1265**         |\n| 8    | Dropping multicollinear features                    | 0.1270         | 0.2427         | 0.1468         | **0.1263**     | **0.1263**         |\n\nThe spike in the linear regression model's RMSE occurs at step 4, where features are added to the dataset. This spike can be attributed to the following factors:\n\n1. **Overfitting**: Adding new features to the dataset can increase the complexity of the linear regression model, which may cause overfitting. This occurs when the model becomes too tailored to the training data, reducing its ability to generalize well on unseen data. As a result, the model's performance, as measured by RMSE, can deteriorate.\n\n2. **Multicollinearity**: Adding new features may introduce multicollinearity, a condition where two or more features are highly correlated. Multicollinearity can lead to unstable estimates of regression coefficients, making it difficult to interpret the feature importances in the model. In turn, this can negatively impact the model's performance.\n\nIt is important to note that the spike in RMSE is specific to the linear regression model. Ridge and Lasso models, which include regularization techniques, are more robust against overfitting and multicollinearity. This is evident in their consistently better performance across the different feature engineering steps, as shown in the table.\n\n- Filtering dominant categories\n- Removing legacy features\n- Removing low correlation features\n- Dropping multicollinear features\n\nThere are several reasons for this:\n\n1. **Regularization advantage**: Before filtering dominant categories and removing multicollinear features, the dataset may contain noisy or highly correlated features. The regularization techniques used in Lasso, Ridge, and Elastic Net models help handle these issues effectively by either shrinking the coefficients or eliminating irrelevant features, making the blended model more robust at this stage.\n\n2. **Diverse models**: The blended model combines the strengths of Lasso, Ridge, and Elastic Net, which are linear models with different regularization techniques. Before filtering steps that remove redundant features or low correlation features, the combined model can capitalize on the strengths of individual models, effectively reducing overfitting and improving overall performance.\n\n3. **Weighted averaging**: The weights assigned to the individual models in the blended model help emphasize the predictions from better-performing models, such as Ridge in this case. This is particularly useful before filtering steps that can reduce the impact of noisy or irrelevant features, as the blended model can still produce robust predictions due to the weighted contributions of each model.\n\nAs a result of these factors, the blended model demonstrates better performance than individual models, especially before the mentioned filtering steps.","metadata":{}},{"cell_type":"markdown","source":"## **Preparing Final Submission**","metadata":{}},{"cell_type":"markdown","source":"The best solution was found using the Blended Linear Regression model before dropping dominant categories.","metadata":{}},{"cell_type":"code","source":"from IPython.display import Image\nImage(\"/kaggle/input/leaderboard/leaderboard.JPG\")","metadata":{"execution":{"iopub.status.busy":"2023-05-08T03:26:25.167490Z","iopub.execute_input":"2023-05-08T03:26:25.167936Z","iopub.status.idle":"2023-05-08T03:26:25.187390Z","shell.execute_reply.started":"2023-05-08T03:26:25.167896Z","shell.execute_reply":"2023-05-08T03:26:25.186094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import Image\nImage(\"/kaggle/input/submissions/submissions.JPG\")","metadata":{"execution":{"iopub.status.busy":"2023-05-08T03:31:06.873592Z","iopub.execute_input":"2023-05-08T03:31:06.874216Z","iopub.status.idle":"2023-05-08T03:31:06.894153Z","shell.execute_reply.started":"2023-05-08T03:31:06.874155Z","shell.execute_reply":"2023-05-08T03:31:06.892724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## References \nIn addition to the hyperlinks in the documents\nhttps://towardsdatascience.com/linear-regression-analysis-on-house-price-in-python-55bbe2cd3fd9\nhttps://towardsdatascience.com/linear-regression-model-with-python-481c89f0f05b\nhttps://machinelearningmastery.com/standardscaler-and-minmaxscaler-transforms-in-python/\nhttps://www.kaggle.com/code/sorkun/house-prices-feature-engineering-lb-0-11775/notebook\nhttps://www.kaggle.com/code/sorkun/house-prices-feature-engineering-lb-0-11775/notebook ","metadata":{}}]}